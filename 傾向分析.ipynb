{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各トップカンファの年次accepted paper url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACL\n",
    "- [2011](http://mirror.aclweb.org/acl2011/accepted_papers.shtml.html)\n",
    "- [2012](http://mirror.aclweb.org/acl2012/program/sub00.asp.html)\n",
    "- [2013](http://www.acl2013.org/site/accepted-papers.html)\n",
    "- [2014](http://acl2014.org/Program.htm)\n",
    "- [2015](http://acl2015.org/accepted_papers.html)\n",
    "- [2016](http://mirror.aclweb.org/acl2016/indexa779.html?article_id=68)\n",
    "- [2017](https://acl2017.wordpress.com/2017/04/05/accepted-papers-and-demonstrations/)\n",
    "- [2018](http://acl2018.org/programme/papers/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMNLP\n",
    "- [2011](http://conferences.inf.ed.ac.uk/emnlp2011/papers.html)\n",
    "- [2012](http://emnlp-conll2012.unige.ch/papers.html)\n",
    "- [2013](http://mirror.aclweb.org/emnlp2013/papers.html)\n",
    "- [2014](http://emnlp2014.org/papers.html)\n",
    "- [2015](http://www.emnlp2015.org/accepted-papers.html)\n",
    "- [2016](https://www.aclweb.org/mirror/emnlp2016/accepted-papers.html)\n",
    "- [2017](http://emnlp2017.net/accepted-papers.html)\n",
    "- 2018はまだ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAACL\n",
    "- 2012 サイトアクセス拒否\n",
    "- [2013](http://naacl2013.naacl.org/PapersAccepted.aspx)\n",
    "- [2014](\n",
    "- [2015](http://naacl.org/naacl-hlt-2015/papers.html)\n",
    "- [2016](http://naacl.org/naacl-hlt-2016/accepted_papers.html)\n",
    "- [2017](\n",
    "- [2018](https://naacl2018.wordpress.com/2018/03/02/list-of-accepted-papers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from util import text_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全文字列を辞書型に格納する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(2011, 2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl = {}\n",
    "for year in years:\n",
    "    acl.update({year: {\n",
    "                'sentences': open(f'./texts/acl_{year}.txt').read().replace('\\n', ''),\n",
    "               'n_papers': len(list(filter(lambda x: x, map(lambda x: x.replace('\\n', ''), open(f'./texts/acl_{year}.txt').readlines()))))\n",
    "    }})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WordCloudによる処理\n",
    "# for year in acl.keys():\n",
    "#     wordcloud = WordCloud().generate(acl[year])\n",
    "#     wordcloud.to_file(f'./images/acl_{year}.png')\n",
    "    \n",
    "# for year in acl.keys():\n",
    "#     wordcloud = WordCloud(max_font_size=40).generate(acl[year])\n",
    "#     wordcloud.to_file(f'./images/acl_{year}_maxfont_40.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_word_df = pd.DataFrame()\n",
    "\n",
    "for year in acl.keys():\n",
    "    common_by_year = pd.DataFrame(text_preprocess(acl[year]['sentences']).most_common(20), columns = [f'word_{year}', f'count_{year}'])\n",
    "    common_by_year[f'count_{year}'] = common_by_year[f'count_{year}'].apply(lambda x: round(x / acl[year]['n_papers'], 3))\n",
    "    common_word_df = pd.concat([common_word_df, \n",
    "                                                            common_by_year], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_2011</th>\n",
       "      <th>count_2011</th>\n",
       "      <th>word_2012</th>\n",
       "      <th>count_2012</th>\n",
       "      <th>word_2013</th>\n",
       "      <th>count_2013</th>\n",
       "      <th>word_2014</th>\n",
       "      <th>count_2014</th>\n",
       "      <th>word_2015</th>\n",
       "      <th>count_2015</th>\n",
       "      <th>word_2016</th>\n",
       "      <th>count_2016</th>\n",
       "      <th>word_2017</th>\n",
       "      <th>count_2017</th>\n",
       "      <th>word_2018</th>\n",
       "      <th>count_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>translation</td>\n",
       "      <td>0.091</td>\n",
       "      <td>translation</td>\n",
       "      <td>0.095</td>\n",
       "      <td>machine</td>\n",
       "      <td>0.115</td>\n",
       "      <td>word</td>\n",
       "      <td>0.088</td>\n",
       "      <td>word</td>\n",
       "      <td>0.113</td>\n",
       "      <td>neural</td>\n",
       "      <td>0.106</td>\n",
       "      <td>neural</td>\n",
       "      <td>0.194</td>\n",
       "      <td>neural</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>language</td>\n",
       "      <td>0.068</td>\n",
       "      <td>learning</td>\n",
       "      <td>0.087</td>\n",
       "      <td>translation</td>\n",
       "      <td>0.075</td>\n",
       "      <td>learning</td>\n",
       "      <td>0.081</td>\n",
       "      <td>neural</td>\n",
       "      <td>0.103</td>\n",
       "      <td>learning</td>\n",
       "      <td>0.089</td>\n",
       "      <td>learning</td>\n",
       "      <td>0.082</td>\n",
       "      <td>language</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>models</td>\n",
       "      <td>0.061</td>\n",
       "      <td>model</td>\n",
       "      <td>0.082</td>\n",
       "      <td>semantic</td>\n",
       "      <td>0.075</td>\n",
       "      <td>semantic</td>\n",
       "      <td>0.074</td>\n",
       "      <td>semantic</td>\n",
       "      <td>0.066</td>\n",
       "      <td>word</td>\n",
       "      <td>0.089</td>\n",
       "      <td>machine</td>\n",
       "      <td>0.082</td>\n",
       "      <td>learning</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model</td>\n",
       "      <td>0.057</td>\n",
       "      <td>machine</td>\n",
       "      <td>0.074</td>\n",
       "      <td>model</td>\n",
       "      <td>0.069</td>\n",
       "      <td>model</td>\n",
       "      <td>0.063</td>\n",
       "      <td>learning</td>\n",
       "      <td>0.063</td>\n",
       "      <td>language</td>\n",
       "      <td>0.083</td>\n",
       "      <td>language</td>\n",
       "      <td>0.079</td>\n",
       "      <td>machine</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>word</td>\n",
       "      <td>0.057</td>\n",
       "      <td>parsing</td>\n",
       "      <td>0.065</td>\n",
       "      <td>statistical</td>\n",
       "      <td>0.063</td>\n",
       "      <td>machine</td>\n",
       "      <td>0.063</td>\n",
       "      <td>machine</td>\n",
       "      <td>0.060</td>\n",
       "      <td>machine</td>\n",
       "      <td>0.061</td>\n",
       "      <td>word</td>\n",
       "      <td>0.074</td>\n",
       "      <td>semantic</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>semantic</td>\n",
       "      <td>0.057</td>\n",
       "      <td>language</td>\n",
       "      <td>0.056</td>\n",
       "      <td>text</td>\n",
       "      <td>0.052</td>\n",
       "      <td>translation</td>\n",
       "      <td>0.063</td>\n",
       "      <td>language</td>\n",
       "      <td>0.053</td>\n",
       "      <td>semantic</td>\n",
       "      <td>0.056</td>\n",
       "      <td>semantic</td>\n",
       "      <td>0.059</td>\n",
       "      <td>word</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>machine</td>\n",
       "      <td>0.054</td>\n",
       "      <td>statistical</td>\n",
       "      <td>0.052</td>\n",
       "      <td>parsing</td>\n",
       "      <td>0.046</td>\n",
       "      <td>extraction</td>\n",
       "      <td>0.060</td>\n",
       "      <td>dependency</td>\n",
       "      <td>0.050</td>\n",
       "      <td>model</td>\n",
       "      <td>0.044</td>\n",
       "      <td>model</td>\n",
       "      <td>0.056</td>\n",
       "      <td>model</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>parsing</td>\n",
       "      <td>0.054</td>\n",
       "      <td>topic</td>\n",
       "      <td>0.052</td>\n",
       "      <td>dependency</td>\n",
       "      <td>0.046</td>\n",
       "      <td>parsing</td>\n",
       "      <td>0.053</td>\n",
       "      <td>parsing</td>\n",
       "      <td>0.047</td>\n",
       "      <td>parsing</td>\n",
       "      <td>0.044</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>0.056</td>\n",
       "      <td>models</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dependency</td>\n",
       "      <td>0.051</td>\n",
       "      <td>word</td>\n",
       "      <td>0.052</td>\n",
       "      <td>learning</td>\n",
       "      <td>0.046</td>\n",
       "      <td>relation</td>\n",
       "      <td>0.049</td>\n",
       "      <td>models</td>\n",
       "      <td>0.044</td>\n",
       "      <td>models</td>\n",
       "      <td>0.044</td>\n",
       "      <td>text</td>\n",
       "      <td>0.050</td>\n",
       "      <td>text</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>learning</td>\n",
       "      <td>0.044</td>\n",
       "      <td>models</td>\n",
       "      <td>0.048</td>\n",
       "      <td>word</td>\n",
       "      <td>0.040</td>\n",
       "      <td>models</td>\n",
       "      <td>0.046</td>\n",
       "      <td>network</td>\n",
       "      <td>0.044</td>\n",
       "      <td>text</td>\n",
       "      <td>0.039</td>\n",
       "      <td>networks</td>\n",
       "      <td>0.038</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>unsupervised</td>\n",
       "      <td>0.037</td>\n",
       "      <td>evaluation</td>\n",
       "      <td>0.048</td>\n",
       "      <td>language</td>\n",
       "      <td>0.040</td>\n",
       "      <td>dependency</td>\n",
       "      <td>0.042</td>\n",
       "      <td>model</td>\n",
       "      <td>0.041</td>\n",
       "      <td>network</td>\n",
       "      <td>0.033</td>\n",
       "      <td>extraction</td>\n",
       "      <td>0.035</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>alignment</td>\n",
       "      <td>0.037</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0.043</td>\n",
       "      <td>prediction</td>\n",
       "      <td>0.040</td>\n",
       "      <td>neural</td>\n",
       "      <td>0.039</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>0.041</td>\n",
       "      <td>topic</td>\n",
       "      <td>0.031</td>\n",
       "      <td>translation</td>\n",
       "      <td>0.035</td>\n",
       "      <td>deep</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>modeling</td>\n",
       "      <td>0.037</td>\n",
       "      <td>chinese</td>\n",
       "      <td>0.043</td>\n",
       "      <td>models</td>\n",
       "      <td>0.034</td>\n",
       "      <td>chinese</td>\n",
       "      <td>0.039</td>\n",
       "      <td>based</td>\n",
       "      <td>0.038</td>\n",
       "      <td>entity</td>\n",
       "      <td>0.031</td>\n",
       "      <td>relation</td>\n",
       "      <td>0.032</td>\n",
       "      <td>networks</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>document</td>\n",
       "      <td>0.034</td>\n",
       "      <td>dependency</td>\n",
       "      <td>0.043</td>\n",
       "      <td>bayesian</td>\n",
       "      <td>0.029</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.039</td>\n",
       "      <td>topic</td>\n",
       "      <td>0.034</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>0.031</td>\n",
       "      <td>question</td>\n",
       "      <td>0.032</td>\n",
       "      <td>entity</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.034</td>\n",
       "      <td>approach</td>\n",
       "      <td>0.039</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.029</td>\n",
       "      <td>detection</td>\n",
       "      <td>0.039</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.034</td>\n",
       "      <td>translation</td>\n",
       "      <td>0.031</td>\n",
       "      <td>parsing</td>\n",
       "      <td>0.032</td>\n",
       "      <td>question</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>extraction</td>\n",
       "      <td>0.034</td>\n",
       "      <td>extraction</td>\n",
       "      <td>0.035</td>\n",
       "      <td>social</td>\n",
       "      <td>0.029</td>\n",
       "      <td>language</td>\n",
       "      <td>0.035</td>\n",
       "      <td>translation</td>\n",
       "      <td>0.034</td>\n",
       "      <td>networks</td>\n",
       "      <td>0.031</td>\n",
       "      <td>dependency</td>\n",
       "      <td>0.032</td>\n",
       "      <td>modeling</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>statistical</td>\n",
       "      <td>0.030</td>\n",
       "      <td>semantic</td>\n",
       "      <td>0.035</td>\n",
       "      <td>data</td>\n",
       "      <td>0.029</td>\n",
       "      <td>text</td>\n",
       "      <td>0.035</td>\n",
       "      <td>embeddings</td>\n",
       "      <td>0.031</td>\n",
       "      <td>relation</td>\n",
       "      <td>0.031</td>\n",
       "      <td>discourse</td>\n",
       "      <td>0.029</td>\n",
       "      <td>attention</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bilingual</td>\n",
       "      <td>0.030</td>\n",
       "      <td>segmentation</td>\n",
       "      <td>0.035</td>\n",
       "      <td>joint</td>\n",
       "      <td>0.023</td>\n",
       "      <td>topic</td>\n",
       "      <td>0.032</td>\n",
       "      <td>convolutional</td>\n",
       "      <td>0.031</td>\n",
       "      <td>embeddings</td>\n",
       "      <td>0.031</td>\n",
       "      <td>generation</td>\n",
       "      <td>0.029</td>\n",
       "      <td>sentence</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>latent</td>\n",
       "      <td>0.030</td>\n",
       "      <td>information</td>\n",
       "      <td>0.035</td>\n",
       "      <td>unsupervised</td>\n",
       "      <td>0.023</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.032</td>\n",
       "      <td>chinese</td>\n",
       "      <td>0.031</td>\n",
       "      <td>dependency</td>\n",
       "      <td>0.028</td>\n",
       "      <td>chinese</td>\n",
       "      <td>0.029</td>\n",
       "      <td>dialogue</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>text</td>\n",
       "      <td>0.030</td>\n",
       "      <td>system</td>\n",
       "      <td>0.035</td>\n",
       "      <td>discourse</td>\n",
       "      <td>0.023</td>\n",
       "      <td>automatic</td>\n",
       "      <td>0.032</td>\n",
       "      <td>text</td>\n",
       "      <td>0.031</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.028</td>\n",
       "      <td>detection</td>\n",
       "      <td>0.026</td>\n",
       "      <td>graph</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_2011  count_2011     word_2012  count_2012     word_2013  \\\n",
       "0    translation       0.091   translation       0.095       machine   \n",
       "1       language       0.068      learning       0.087   translation   \n",
       "2         models       0.061         model       0.082      semantic   \n",
       "3          model       0.057       machine       0.074         model   \n",
       "4           word       0.057       parsing       0.065   statistical   \n",
       "5       semantic       0.057      language       0.056          text   \n",
       "6        machine       0.054   statistical       0.052       parsing   \n",
       "7        parsing       0.054         topic       0.052    dependency   \n",
       "8     dependency       0.051          word       0.052      learning   \n",
       "9       learning       0.044        models       0.048          word   \n",
       "10  unsupervised       0.037    evaluation       0.048      language   \n",
       "11     alignment       0.037       lexical       0.043    prediction   \n",
       "12      modeling       0.037       chinese       0.043        models   \n",
       "13      document       0.034    dependency       0.043      bayesian   \n",
       "14     sentiment       0.034      approach       0.039     sentiment   \n",
       "15    extraction       0.034    extraction       0.035        social   \n",
       "16   statistical       0.030      semantic       0.035          data   \n",
       "17     bilingual       0.030  segmentation       0.035         joint   \n",
       "18        latent       0.030   information       0.035  unsupervised   \n",
       "19          text       0.030        system       0.035     discourse   \n",
       "\n",
       "    count_2013    word_2014  count_2014      word_2015  count_2015  \\\n",
       "0        0.115         word       0.088           word       0.113   \n",
       "1        0.075     learning       0.081         neural       0.103   \n",
       "2        0.075     semantic       0.074       semantic       0.066   \n",
       "3        0.069        model       0.063       learning       0.063   \n",
       "4        0.063      machine       0.063        machine       0.060   \n",
       "5        0.052  translation       0.063       language       0.053   \n",
       "6        0.046   extraction       0.060     dependency       0.050   \n",
       "7        0.046      parsing       0.053        parsing       0.047   \n",
       "8        0.046     relation       0.049         models       0.044   \n",
       "9        0.040       models       0.046        network       0.044   \n",
       "10       0.040   dependency       0.042          model       0.041   \n",
       "11       0.040       neural       0.039      knowledge       0.041   \n",
       "12       0.034      chinese       0.039          based       0.038   \n",
       "13       0.029    sentiment       0.039          topic       0.034   \n",
       "14       0.029    detection       0.039      sentiment       0.034   \n",
       "15       0.029     language       0.035    translation       0.034   \n",
       "16       0.029         text       0.035     embeddings       0.031   \n",
       "17       0.023        topic       0.032  convolutional       0.031   \n",
       "18       0.023     analysis       0.032        chinese       0.031   \n",
       "19       0.023    automatic       0.032           text       0.031   \n",
       "\n",
       "         word_2016  count_2016    word_2017  count_2017  word_2018  count_2018  \n",
       "0           neural       0.106       neural       0.194     neural       0.176  \n",
       "1         learning       0.089     learning       0.082   language       0.074  \n",
       "2             word       0.089      machine       0.082   learning       0.069  \n",
       "3         language       0.083     language       0.079    machine       0.064  \n",
       "4          machine       0.061         word       0.074   semantic       0.061  \n",
       "5         semantic       0.056     semantic       0.059       word       0.049  \n",
       "6            model       0.044        model       0.056      model       0.047  \n",
       "7          parsing       0.044    knowledge       0.056     models       0.039  \n",
       "8           models       0.044         text       0.050       text       0.039  \n",
       "9             text       0.039     networks       0.038  knowledge       0.037  \n",
       "10         network       0.033   extraction       0.035  sentiment       0.034  \n",
       "11           topic       0.031  translation       0.035       deep       0.032  \n",
       "12          entity       0.031     relation       0.032   networks       0.032  \n",
       "13       knowledge       0.031     question       0.032     entity       0.032  \n",
       "14     translation       0.031      parsing       0.032   question       0.029  \n",
       "15        networks       0.031   dependency       0.032   modeling       0.029  \n",
       "16        relation       0.031    discourse       0.029  attention       0.027  \n",
       "17      embeddings       0.031   generation       0.029   sentence       0.027  \n",
       "18      dependency       0.028      chinese       0.029   dialogue       0.025  \n",
       "19  classification       0.028    detection       0.026      graph       0.025  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_words = ['translation', 'learning', 'machine', 'semantic', 'model', 'statistical', 'relation', 'neural', 'word', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for choice_word in choice_words:\n",
    "    for i, word_score in common_word_df.iterrows():\n",
    "        choice_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(2011, 2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emnlp = {}\n",
    "for year in years:\n",
    "    emnlp.update({year: {\n",
    "                'sentences': open(f'./texts/emnlp_{year}.txt').read().replace('\\n', ''),\n",
    "               'n_papers': len(list(filter(lambda x: x, map(lambda x: x.replace('\\n', ''), open(f'./texts/emnlp_{year}.txt').readlines()))))\n",
    "    }})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_word_df = pd.DataFrame()\n",
    "\n",
    "for year in emnlp.keys():\n",
    "    common_by_year = pd.DataFrame(text_preprocess(emnlp[year]['sentences']).most_common(20), columns = [f'word_{year}', f'count_{year}'])\n",
    "    common_by_year[f'count_{year}'] = common_by_year[f'count_{year}'].apply(lambda x: round(x / emnlp[year]['n_papers'], 3))\n",
    "    common_word_df = pd.concat([common_word_df, \n",
    "                                                            common_by_year], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_2011</th>\n",
       "      <th>count_2011</th>\n",
       "      <th>word_2012</th>\n",
       "      <th>count_2012</th>\n",
       "      <th>word_2013</th>\n",
       "      <th>count_2013</th>\n",
       "      <th>word_2014</th>\n",
       "      <th>count_2014</th>\n",
       "      <th>word_2015</th>\n",
       "      <th>count_2015</th>\n",
       "      <th>word_2016</th>\n",
       "      <th>count_2016</th>\n",
       "      <th>word_2017</th>\n",
       "      <th>count_2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>machine</td>\n",
       "      <td>0.094</td>\n",
       "      <td>model</td>\n",
       "      <td>0.101</td>\n",
       "      <td>model</td>\n",
       "      <td>0.083</td>\n",
       "      <td>word</td>\n",
       "      <td>0.103</td>\n",
       "      <td>neural</td>\n",
       "      <td>0.106</td>\n",
       "      <td>neural</td>\n",
       "      <td>0.207</td>\n",
       "      <td>neural</td>\n",
       "      <td>0.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dependency</td>\n",
       "      <td>0.081</td>\n",
       "      <td>language</td>\n",
       "      <td>0.072</td>\n",
       "      <td>machine</td>\n",
       "      <td>0.083</td>\n",
       "      <td>machine</td>\n",
       "      <td>0.089</td>\n",
       "      <td>word</td>\n",
       "      <td>0.100</td>\n",
       "      <td>learning</td>\n",
       "      <td>0.124</td>\n",
       "      <td>machine</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model</td>\n",
       "      <td>0.067</td>\n",
       "      <td>word</td>\n",
       "      <td>0.072</td>\n",
       "      <td>word</td>\n",
       "      <td>0.073</td>\n",
       "      <td>semantic</td>\n",
       "      <td>0.076</td>\n",
       "      <td>models</td>\n",
       "      <td>0.082</td>\n",
       "      <td>language</td>\n",
       "      <td>0.087</td>\n",
       "      <td>learning</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>models</td>\n",
       "      <td>0.067</td>\n",
       "      <td>learning</td>\n",
       "      <td>0.072</td>\n",
       "      <td>models</td>\n",
       "      <td>0.068</td>\n",
       "      <td>model</td>\n",
       "      <td>0.071</td>\n",
       "      <td>translation</td>\n",
       "      <td>0.082</td>\n",
       "      <td>parsing</td>\n",
       "      <td>0.076</td>\n",
       "      <td>word</td>\n",
       "      <td>0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>semantic</td>\n",
       "      <td>0.067</td>\n",
       "      <td>models</td>\n",
       "      <td>0.065</td>\n",
       "      <td>language</td>\n",
       "      <td>0.063</td>\n",
       "      <td>translation</td>\n",
       "      <td>0.058</td>\n",
       "      <td>language</td>\n",
       "      <td>0.079</td>\n",
       "      <td>models</td>\n",
       "      <td>0.076</td>\n",
       "      <td>semantic</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>word</td>\n",
       "      <td>0.067</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>0.065</td>\n",
       "      <td>learning</td>\n",
       "      <td>0.058</td>\n",
       "      <td>neural</td>\n",
       "      <td>0.054</td>\n",
       "      <td>model</td>\n",
       "      <td>0.076</td>\n",
       "      <td>semantic</td>\n",
       "      <td>0.073</td>\n",
       "      <td>language</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>translation</td>\n",
       "      <td>0.054</td>\n",
       "      <td>based</td>\n",
       "      <td>0.058</td>\n",
       "      <td>semantic</td>\n",
       "      <td>0.049</td>\n",
       "      <td>learning</td>\n",
       "      <td>0.045</td>\n",
       "      <td>learning</td>\n",
       "      <td>0.069</td>\n",
       "      <td>machine</td>\n",
       "      <td>0.065</td>\n",
       "      <td>representations</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>generation</td>\n",
       "      <td>0.040</td>\n",
       "      <td>machine</td>\n",
       "      <td>0.058</td>\n",
       "      <td>extraction</td>\n",
       "      <td>0.044</td>\n",
       "      <td>statistical</td>\n",
       "      <td>0.045</td>\n",
       "      <td>parsing</td>\n",
       "      <td>0.066</td>\n",
       "      <td>translation</td>\n",
       "      <td>0.065</td>\n",
       "      <td>translation</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>language</td>\n",
       "      <td>0.040</td>\n",
       "      <td>semantic</td>\n",
       "      <td>0.058</td>\n",
       "      <td>translation</td>\n",
       "      <td>0.044</td>\n",
       "      <td>inference</td>\n",
       "      <td>0.040</td>\n",
       "      <td>machine</td>\n",
       "      <td>0.063</td>\n",
       "      <td>networks</td>\n",
       "      <td>0.055</td>\n",
       "      <td>model</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>relations</td>\n",
       "      <td>0.034</td>\n",
       "      <td>dependency</td>\n",
       "      <td>0.050</td>\n",
       "      <td>statistical</td>\n",
       "      <td>0.034</td>\n",
       "      <td>chinese</td>\n",
       "      <td>0.040</td>\n",
       "      <td>semantic</td>\n",
       "      <td>0.063</td>\n",
       "      <td>text</td>\n",
       "      <td>0.055</td>\n",
       "      <td>relation</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>information</td>\n",
       "      <td>0.034</td>\n",
       "      <td>parsing</td>\n",
       "      <td>0.043</td>\n",
       "      <td>joint</td>\n",
       "      <td>0.029</td>\n",
       "      <td>extraction</td>\n",
       "      <td>0.040</td>\n",
       "      <td>text</td>\n",
       "      <td>0.057</td>\n",
       "      <td>word</td>\n",
       "      <td>0.055</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>noun</td>\n",
       "      <td>0.034</td>\n",
       "      <td>statistical</td>\n",
       "      <td>0.043</td>\n",
       "      <td>chinese</td>\n",
       "      <td>0.029</td>\n",
       "      <td>topic</td>\n",
       "      <td>0.040</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.051</td>\n",
       "      <td>model</td>\n",
       "      <td>0.055</td>\n",
       "      <td>models</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>statistical</td>\n",
       "      <td>0.034</td>\n",
       "      <td>inference</td>\n",
       "      <td>0.036</td>\n",
       "      <td>sentence</td>\n",
       "      <td>0.029</td>\n",
       "      <td>segmentation</td>\n",
       "      <td>0.036</td>\n",
       "      <td>embeddings</td>\n",
       "      <td>0.051</td>\n",
       "      <td>network</td>\n",
       "      <td>0.051</td>\n",
       "      <td>parsing</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.034</td>\n",
       "      <td>tagging</td>\n",
       "      <td>0.036</td>\n",
       "      <td>topic</td>\n",
       "      <td>0.029</td>\n",
       "      <td>models</td>\n",
       "      <td>0.036</td>\n",
       "      <td>network</td>\n",
       "      <td>0.048</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.047</td>\n",
       "      <td>deep</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>approach</td>\n",
       "      <td>0.027</td>\n",
       "      <td>unsupervised</td>\n",
       "      <td>0.036</td>\n",
       "      <td>search</td>\n",
       "      <td>0.029</td>\n",
       "      <td>language</td>\n",
       "      <td>0.036</td>\n",
       "      <td>discourse</td>\n",
       "      <td>0.048</td>\n",
       "      <td>extraction</td>\n",
       "      <td>0.047</td>\n",
       "      <td>text</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>discourse</td>\n",
       "      <td>0.027</td>\n",
       "      <td>discourse</td>\n",
       "      <td>0.029</td>\n",
       "      <td>based</td>\n",
       "      <td>0.029</td>\n",
       "      <td>approach</td>\n",
       "      <td>0.031</td>\n",
       "      <td>joint</td>\n",
       "      <td>0.048</td>\n",
       "      <td>generation</td>\n",
       "      <td>0.047</td>\n",
       "      <td>embeddings</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>structure</td>\n",
       "      <td>0.027</td>\n",
       "      <td>translation</td>\n",
       "      <td>0.029</td>\n",
       "      <td>distributional</td>\n",
       "      <td>0.024</td>\n",
       "      <td>discourse</td>\n",
       "      <td>0.031</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.045</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.044</td>\n",
       "      <td>question</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sentence</td>\n",
       "      <td>0.027</td>\n",
       "      <td>topic</td>\n",
       "      <td>0.029</td>\n",
       "      <td>neural</td>\n",
       "      <td>0.024</td>\n",
       "      <td>joint</td>\n",
       "      <td>0.031</td>\n",
       "      <td>networks</td>\n",
       "      <td>0.045</td>\n",
       "      <td>deep</td>\n",
       "      <td>0.040</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>syntactic</td>\n",
       "      <td>0.027</td>\n",
       "      <td>order</td>\n",
       "      <td>0.029</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0.024</td>\n",
       "      <td>dependency</td>\n",
       "      <td>0.031</td>\n",
       "      <td>extraction</td>\n",
       "      <td>0.042</td>\n",
       "      <td>data</td>\n",
       "      <td>0.036</td>\n",
       "      <td>based</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.027</td>\n",
       "      <td>resolution</td>\n",
       "      <td>0.029</td>\n",
       "      <td>coreference</td>\n",
       "      <td>0.024</td>\n",
       "      <td>text</td>\n",
       "      <td>0.031</td>\n",
       "      <td>modeling</td>\n",
       "      <td>0.039</td>\n",
       "      <td>dependency</td>\n",
       "      <td>0.036</td>\n",
       "      <td>information</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_2011  count_2011     word_2012  count_2012       word_2013  \\\n",
       "0       machine       0.094         model       0.101           model   \n",
       "1    dependency       0.081      language       0.072         machine   \n",
       "2         model       0.067          word       0.072            word   \n",
       "3        models       0.067      learning       0.072          models   \n",
       "4      semantic       0.067        models       0.065        language   \n",
       "5          word       0.067     syntactic       0.065        learning   \n",
       "6   translation       0.054         based       0.058        semantic   \n",
       "7    generation       0.040       machine       0.058      extraction   \n",
       "8      language       0.040      semantic       0.058     translation   \n",
       "9     relations       0.034    dependency       0.050     statistical   \n",
       "10  information       0.034       parsing       0.043           joint   \n",
       "11         noun       0.034   statistical       0.043         chinese   \n",
       "12  statistical       0.034     inference       0.036        sentence   \n",
       "13    sentiment       0.034       tagging       0.036           topic   \n",
       "14     approach       0.027  unsupervised       0.036          search   \n",
       "15    discourse       0.027     discourse       0.029           based   \n",
       "16    structure       0.027   translation       0.029  distributional   \n",
       "17     sentence       0.027         topic       0.029          neural   \n",
       "18    syntactic       0.027         order       0.029         lexical   \n",
       "19         tree       0.027    resolution       0.029     coreference   \n",
       "\n",
       "    count_2013     word_2014  count_2014    word_2015  count_2015  \\\n",
       "0        0.083          word       0.103       neural       0.106   \n",
       "1        0.083       machine       0.089         word       0.100   \n",
       "2        0.073      semantic       0.076       models       0.082   \n",
       "3        0.068         model       0.071  translation       0.082   \n",
       "4        0.063   translation       0.058     language       0.079   \n",
       "5        0.058        neural       0.054        model       0.076   \n",
       "6        0.049      learning       0.045     learning       0.069   \n",
       "7        0.044   statistical       0.045      parsing       0.066   \n",
       "8        0.044     inference       0.040      machine       0.063   \n",
       "9        0.034       chinese       0.040     semantic       0.063   \n",
       "10       0.029    extraction       0.040         text       0.057   \n",
       "11       0.029         topic       0.040     analysis       0.051   \n",
       "12       0.029  segmentation       0.036   embeddings       0.051   \n",
       "13       0.029        models       0.036      network       0.048   \n",
       "14       0.029      language       0.036    discourse       0.048   \n",
       "15       0.029      approach       0.031        joint       0.048   \n",
       "16       0.024     discourse       0.031    sentiment       0.045   \n",
       "17       0.024         joint       0.031     networks       0.045   \n",
       "18       0.024    dependency       0.031   extraction       0.042   \n",
       "19       0.024          text       0.031     modeling       0.039   \n",
       "\n",
       "         word_2016  count_2016        word_2017  count_2017  \n",
       "0           neural       0.207           neural       0.169  \n",
       "1         learning       0.124          machine       0.099  \n",
       "2         language       0.087         learning       0.096  \n",
       "3          parsing       0.076             word       0.093  \n",
       "4           models       0.076         semantic       0.055  \n",
       "5         semantic       0.073         language       0.049  \n",
       "6          machine       0.065  representations       0.047  \n",
       "7      translation       0.065      translation       0.044  \n",
       "8         networks       0.055            model       0.041  \n",
       "9             text       0.055         relation       0.035  \n",
       "10            word       0.055        sentiment       0.035  \n",
       "11           model       0.055           models       0.035  \n",
       "12         network       0.051          parsing       0.035  \n",
       "13       sentiment       0.047             deep       0.032  \n",
       "14      extraction       0.047             text       0.032  \n",
       "15      generation       0.047       embeddings       0.032  \n",
       "16  classification       0.044         question       0.029  \n",
       "17            deep       0.040        knowledge       0.029  \n",
       "18            data       0.036            based       0.026  \n",
       "19      dependency       0.036      information       0.026  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
